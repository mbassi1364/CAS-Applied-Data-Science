{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:LightSlateGray;\">Data Science Project Assessment of Database Performance Degradation</span>\n",
    "_CAS ADS 2019/2020 University of Berne_<br/>\n",
    "_Author: Marco Bassi_, September 20, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "### Situation\n",
    "The SBB project KiHub operates the CUS platform, a datahub for the real-time data of the Swiss public transport. One of the core components it the CUS DB, an Oracle RDBMS. There is the **CUS DB Prod** for the productive environment, and the **CUS DB Inte** for the release test environment. Each database runs on its own, dedicated Oracle Data Appliance (ODA). Each database consists two database instances, running in cluster mode (Oracle Real Application Cluster).\n",
    "\n",
    "Upon an upgrade of its grid infrastructure, the performance of the CUS DB Inte deteriorated to a degree, where it wouldn't meet anymore its purpose for the release test. The performance issues manifested themselves mainly in a massive degradation of the cluster-related wait times. \n",
    "\n",
    "In the beginning of August, a number of patches was applied to improve the performance. The goal of this analysis is to evaluate the performance of the CUS DB Inte, by compairing it with the CUS DB Prod. For this purpose, some selected system statistics are gathered from the _Oracle dynamic performance view_ DBA_HIST_SYSSTAT. This view contains hourly snapshots of historicised system statistics.\n",
    "The statistics are running sums, with their values beeing reset upon system restart.\n",
    "\n",
    "### Data Analysis\n",
    "The analysis is made of three parts:\n",
    "1. Part 1 contains the data cleansing.\n",
    "2. Part 2 analyses the system load of the two databases. Similar system load is a major precondition for drawing conclusions of the performance of the CUS DB Inte, when compaired to CUS DB Prod.\n",
    "3. Part 3 specifically analyses statistics related to the Global Cache (GC). GC is involved when one cluster database instance requires data currently held in the Local Cache (LC) of the other cluster database instance. The handling of this situation is ruled by a sophisticated protocol, which however is out of scope of this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:LightSlateGray;\">Part 1 &mdash; Data Cleansing</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'C:/Users/ue85374/data/CAS-ADS/Git.repos/CAS-Applied-Data-Science/Data-Science-Project/project.1/statistiken.2019-08-22T0000-bis-2019-08-28T1000/data'"
      ],
      "text/latex": [
       "'C:/Users/ue85374/data/CAS-ADS/Git.repos/CAS-Applied-Data-Science/Data-Science-Project/project.1/statistiken.2019-08-22T0000-bis-2019-08-28T1000/data'"
      ],
      "text/markdown": [
       "'C:/Users/ue85374/data/CAS-ADS/Git.repos/CAS-Applied-Data-Science/Data-Science-Project/project.1/statistiken.2019-08-22T0000-bis-2019-08-28T1000/data'"
      ],
      "text/plain": [
       "[1] \"C:/Users/ue85374/data/CAS-ADS/Git.repos/CAS-Applied-Data-Science/Data-Science-Project/project.1/statistiken.2019-08-22T0000-bis-2019-08-28T1000/data\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(data.table)\n",
    "setwd('../../data')\n",
    "getwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t232897 obs. of  6 variables:\n",
      " $ BEGIN_INTERVAL_TIME: chr  \"2019-08-22 00:00:05\" \"2019-08-22 00:00:05\" \"2019-08-22 00:00:05\" \"2019-08-22 00:00:05\" ...\n",
      " $ END_INTERVAL_TIME  : chr  \"2019-08-22 01:00:22\" \"2019-08-22 01:00:22\" \"2019-08-22 01:00:22\" \"2019-08-22 01:00:22\" ...\n",
      " $ SNAP_ID            : int  20070 20070 20070 20070 20070 20070 20070 20070 20070 20070 ...\n",
      " $ INSTANCE_NUMBER    : int  2 2 2 2 2 2 2 2 2 2 ...\n",
      " $ STAT_NAME          : chr  \"active txn count during cleanout\" \"ADG parselock X get attempts\" \"ADG parselock X get successes\" \"application wait time\" ...\n",
      " $ VALUE              : num  94067174 0 0 24287453 0 ...\n"
     ]
    }
   ],
   "source": [
    "daten.inte <- read.csv2(file=\"dba_hist_sysstat.inte.dsv\", sep=\";\", dec=\".\", stringsAsFactors=F)\n",
    "str(daten.inte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t239008 obs. of  6 variables:\n",
      " $ BEGIN_INTERVAL_TIME: chr  \"2019-08-22 00:00:14\" \"2019-08-22 00:00:14\" \"2019-08-22 00:00:14\" \"2019-08-22 00:00:14\" ...\n",
      " $ END_INTERVAL_TIME  : chr  \"2019-08-22 01:00:16\" \"2019-08-22 01:00:16\" \"2019-08-22 01:00:16\" \"2019-08-22 01:00:16\" ...\n",
      " $ SNAP_ID            : int  35567 35567 35567 35567 35567 35567 35567 35567 35567 35567 ...\n",
      " $ INSTANCE_NUMBER    : int  1 1 1 1 1 1 1 1 1 1 ...\n",
      " $ STAT_NAME          : chr  \"active txn count during cleanout\" \"ADG parselock X get attempts\" \"ADG parselock X get successes\" \"application wait time\" ...\n",
      " $ VALUE              : num  5.11e+08 0.00 0.00 8.39e+07 1.19e+02 ...\n"
     ]
    }
   ],
   "source": [
    "daten.prod <- read.csv2(file=\"dba_hist_sysstat.prod.dsv\", sep=\";\", dec=\".\", stringsAsFactors=F)\n",
    "str(daten.prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>BEGIN_INTERVAL_TIME</th><th scope=col>END_INTERVAL_TIME</th><th scope=col>SNAP_ID</th><th scope=col>INSTANCE_NUMBER</th><th scope=col>STAT_NAME</th><th scope=col>VALUE</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>2019-08-22 00:00:14             </td><td>2019-08-22 01:00:16             </td><td>35567                           </td><td>1                               </td><td>active txn count during cleanout</td><td>511403667                       </td></tr>\n",
       "\t<tr><td>2019-08-22 00:00:14             </td><td>2019-08-22 01:00:16             </td><td>35567                           </td><td>1                               </td><td>ADG parselock X get attempts    </td><td>        0                       </td></tr>\n",
       "\t<tr><td>2019-08-22 00:00:14             </td><td>2019-08-22 01:00:16             </td><td>35567                           </td><td>1                               </td><td>ADG parselock X get successes   </td><td>        0                       </td></tr>\n",
       "\t<tr><td>2019-08-22 00:00:14             </td><td>2019-08-22 01:00:16             </td><td>35567                           </td><td>1                               </td><td>application wait time           </td><td> 83919815                       </td></tr>\n",
       "\t<tr><td>2019-08-22 00:00:14             </td><td>2019-08-22 01:00:16             </td><td>35567                           </td><td>1                               </td><td>auto extends on undo tablespace </td><td>      119                       </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllll}\n",
       " BEGIN\\_INTERVAL\\_TIME & END\\_INTERVAL\\_TIME & SNAP\\_ID & INSTANCE\\_NUMBER & STAT\\_NAME & VALUE\\\\\n",
       "\\hline\n",
       "\t 2019-08-22 00:00:14              & 2019-08-22 01:00:16              & 35567                            & 1                                & active txn count during cleanout & 511403667                       \\\\\n",
       "\t 2019-08-22 00:00:14              & 2019-08-22 01:00:16              & 35567                            & 1                                & ADG parselock X get attempts     &         0                       \\\\\n",
       "\t 2019-08-22 00:00:14              & 2019-08-22 01:00:16              & 35567                            & 1                                & ADG parselock X get successes    &         0                       \\\\\n",
       "\t 2019-08-22 00:00:14              & 2019-08-22 01:00:16              & 35567                            & 1                                & application wait time            &  83919815                       \\\\\n",
       "\t 2019-08-22 00:00:14              & 2019-08-22 01:00:16              & 35567                            & 1                                & auto extends on undo tablespace  &       119                       \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| BEGIN_INTERVAL_TIME | END_INTERVAL_TIME | SNAP_ID | INSTANCE_NUMBER | STAT_NAME | VALUE |\n",
       "|---|---|---|---|---|---|\n",
       "| 2019-08-22 00:00:14              | 2019-08-22 01:00:16              | 35567                            | 1                                | active txn count during cleanout | 511403667                        |\n",
       "| 2019-08-22 00:00:14              | 2019-08-22 01:00:16              | 35567                            | 1                                | ADG parselock X get attempts     |         0                        |\n",
       "| 2019-08-22 00:00:14              | 2019-08-22 01:00:16              | 35567                            | 1                                | ADG parselock X get successes    |         0                        |\n",
       "| 2019-08-22 00:00:14              | 2019-08-22 01:00:16              | 35567                            | 1                                | application wait time            |  83919815                        |\n",
       "| 2019-08-22 00:00:14              | 2019-08-22 01:00:16              | 35567                            | 1                                | auto extends on undo tablespace  |       119                        |\n",
       "\n"
      ],
      "text/plain": [
       "  BEGIN_INTERVAL_TIME END_INTERVAL_TIME   SNAP_ID INSTANCE_NUMBER\n",
       "1 2019-08-22 00:00:14 2019-08-22 01:00:16 35567   1              \n",
       "2 2019-08-22 00:00:14 2019-08-22 01:00:16 35567   1              \n",
       "3 2019-08-22 00:00:14 2019-08-22 01:00:16 35567   1              \n",
       "4 2019-08-22 00:00:14 2019-08-22 01:00:16 35567   1              \n",
       "5 2019-08-22 00:00:14 2019-08-22 01:00:16 35567   1              \n",
       "  STAT_NAME                        VALUE    \n",
       "1 active txn count during cleanout 511403667\n",
       "2 ADG parselock X get attempts             0\n",
       "3 ADG parselock X get successes            0\n",
       "4 application wait time             83919815\n",
       "5 auto extends on undo tablespace        119"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Use data.table library\n",
    "dt.inte <- data.table(daten.inte)\n",
    "dt.prod <- data.table(daten.prod)\n",
    "head(dt.prod, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As the statistics are running sums, they have to be \"nulled\" with respect to the oldest snapshot common to the two instances of a cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0"
      ],
      "text/latex": [
       "0"
      ],
      "text/markdown": [
       "0"
      ],
      "text/plain": [
       "[1] 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes 'data.table' and 'data.frame':\t232897 obs. of  8 variables:\n",
      " $ INSTANCE_NUMBER    : int  1 1 1 1 1 1 1 1 1 1 ...\n",
      " $ STAT_NAME          : chr  \"ADG parselock X get attempts\" \"ADG parselock X get attempts\" \"ADG parselock X get attempts\" \"ADG parselock X get attempts\" ...\n",
      " $ BEGIN_INTERVAL_TIME: chr  \"2019-08-22 00:00:05\" \"2019-08-22 01:00:22\" \"2019-08-22 02:00:46\" \"2019-08-22 03:00:40\" ...\n",
      " $ END_INTERVAL_TIME  : chr  \"2019-08-22 01:00:22\" \"2019-08-22 02:00:46\" \"2019-08-22 03:00:40\" \"2019-08-22 04:00:21\" ...\n",
      " $ SNAP_ID            : int  20070 20071 20072 20073 20074 20075 20076 20077 20078 20079 ...\n",
      " $ VALUE              : num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ VALUE0             : num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ offsetValue        : num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " - attr(*, \".internal.selfref\")=<externalptr> \n",
      " - attr(*, \"sorted\")= chr  \"INSTANCE_NUMBER\" \"STAT_NAME\"\n"
     ]
    }
   ],
   "source": [
    "# find the minimum snaphost ID for the CUS DB Inte data\n",
    "minsnap.inte <- dt.inte[, min(SNAP_ID), by=INSTANCE_NUMBER]\n",
    "\n",
    "# select the minimum snapshot data\n",
    "mindt.inte <- merge(dt.inte, minsnap.inte, by.x=c(\"INSTANCE_NUMBER\", \"SNAP_ID\"), by.y=c(\"INSTANCE_NUMBER\", \"V1\"), all=F)\n",
    "dtNulled.inte <- merge(dt.inte, mindt.inte[, list(INSTANCE_NUMBER, STAT_NAME, VALUE)] , by=c(\"INSTANCE_NUMBER\", \"STAT_NAME\"), suffixes=c(\"\", 0),all.x = T)\n",
    "\n",
    "# Check if there are statisctics having value NA\n",
    "sum(is.na(dtNulled.inte[, c('VALUE', 'VALUE0')]))  # must be 0\n",
    "\n",
    "# Compute the nulled value, i.e. the statics value of all snapshots and statistics wrt. the minimum snapshot data\n",
    "dtNulled.inte[, offsetValue := VALUE - VALUE0]\n",
    "str(dtNulled.inte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0"
      ],
      "text/latex": [
       "0"
      ],
      "text/markdown": [
       "0"
      ],
      "text/plain": [
       "[1] 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes 'data.table' and 'data.frame':\t239008 obs. of  8 variables:\n",
      " $ INSTANCE_NUMBER    : int  1 1 1 1 1 1 1 1 1 1 ...\n",
      " $ STAT_NAME          : chr  \"ADG parselock X get attempts\" \"ADG parselock X get attempts\" \"ADG parselock X get attempts\" \"ADG parselock X get attempts\" ...\n",
      " $ BEGIN_INTERVAL_TIME: chr  \"2019-08-22 00:00:14\" \"2019-08-22 01:00:16\" \"2019-08-22 02:00:01\" \"2019-08-22 03:00:07\" ...\n",
      " $ END_INTERVAL_TIME  : chr  \"2019-08-22 01:00:16\" \"2019-08-22 02:00:01\" \"2019-08-22 03:00:07\" \"2019-08-22 04:00:20\" ...\n",
      " $ SNAP_ID            : int  35567 35568 35569 35570 35571 35572 35573 35574 35575 35576 ...\n",
      " $ VALUE              : num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ VALUE0             : num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ offsetValue        : num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " - attr(*, \".internal.selfref\")=<externalptr> \n",
      " - attr(*, \"sorted\")= chr  \"INSTANCE_NUMBER\" \"STAT_NAME\"\n"
     ]
    }
   ],
   "source": [
    "# same procedure for CUS DB Prod data\n",
    "minsnap.prod <- dt.prod[, min(SNAP_ID), by=INSTANCE_NUMBER]\n",
    "mindt.prod <- merge(dt.prod, minsnap.prod, by.x=c(\"INSTANCE_NUMBER\", \"SNAP_ID\"), by.y=c(\"INSTANCE_NUMBER\", \"V1\"), all=F)\n",
    "dtNulled.prod <- merge(dt.prod, mindt.prod[, list(INSTANCE_NUMBER, STAT_NAME, VALUE)] , by=c(\"INSTANCE_NUMBER\", \"STAT_NAME\"), suffixes=c(\"\", 0),all.x = T)\n",
    "\n",
    "sum(is.na(dtNulled.prod[, c('VALUE', 'VALUE0')]))  # must be 0\n",
    "dtNulled.prod[, offsetValue := VALUE - VALUE0]\n",
    "str(dtNulled.prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes 'data.table' and 'data.frame':\t239008 obs. of  11 variables:\n",
      " $ INSTANCE_NUMBER    : int  1 1 1 1 1 1 1 1 1 1 ...\n",
      " $ STAT_NAME          : chr  \"ADG parselock X get attempts\" \"ADG parselock X get attempts\" \"ADG parselock X get attempts\" \"ADG parselock X get attempts\" ...\n",
      " $ BEGIN_INTERVAL_TIME: chr  \"2019-08-22 00:00:14\" \"2019-08-22 01:00:16\" \"2019-08-22 02:00:01\" \"2019-08-22 03:00:07\" ...\n",
      " $ END_INTERVAL_TIME  : chr  \"2019-08-22 01:00:16\" \"2019-08-22 02:00:01\" \"2019-08-22 03:00:07\" \"2019-08-22 04:00:20\" ...\n",
      " $ SNAP_ID            : int  35567 35568 35569 35570 35571 35572 35573 35574 35575 35576 ...\n",
      " $ VALUE              : num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ VALUE0             : num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ offsetValue        : num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ beginInterval      : POSIXct, format: \"2019-08-22 00:00:14\" \"2019-08-22 01:00:16\" ...\n",
      " $ endInterval        : POSIXct, format: \"2019-08-22 01:00:16\" \"2019-08-22 02:00:01\" ...\n",
      " $ snapHour           : POSIXct, format: \"2019-08-22 00:00:00\" \"2019-08-22 01:00:00\" ...\n",
      " - attr(*, \".internal.selfref\")=<externalptr> \n",
      " - attr(*, \"sorted\")= chr  \"INSTANCE_NUMBER\" \"STAT_NAME\"\n"
     ]
    }
   ],
   "source": [
    "# Compute datetime values from character strings\n",
    "dtNulled.inte[, beginInterval := as.POSIXct(BEGIN_INTERVAL_TIME, format=\"%Y-%m-%d %H:%M:%S\")]\n",
    "dtNulled.inte[, endInterval := as.POSIXct(END_INTERVAL_TIME, format=\"%Y-%m-%d %H:%M:%S\")]\n",
    "dtNulled.inte[, snapHour := as.POSIXct(round(beginInterval, units=\"hours\"))]\n",
    "\n",
    "dtNulled.prod[, beginInterval := as.POSIXct(BEGIN_INTERVAL_TIME, format=\"%Y-%m-%d %H:%M:%S\")]\n",
    "dtNulled.prod[, endInterval := as.POSIXct(END_INTERVAL_TIME, format=\"%Y-%m-%d %H:%M:%S\")]\n",
    "dtNulled.prod[, snapHour := as.POSIXct(round(beginInterval, units=\"hours\"))]\n",
    "str(dtNulled.prod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**N.B.** The field _snapHour_ is the time the hourly snapshot was taken, rounded to the hour. As the begin of the snapshot interval may vary for a few seconds or even minutes &mdash; between instances of the same database or different databases &mdash; this field helps to relate the snapshots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-style: italic; color: LightSlateGray; font-size:1.1em;\">There are some lengty tests to show the snapshot intervals are identical and comparable. These tests are skipped here.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes 'data.table' and 'data.frame':\t114751 obs. of  4 variables:\n",
      " $ snapHour  : POSIXct, format: \"2019-08-22 00:00:00\" \"2019-08-22 00:00:00\" ...\n",
      " $ STAT_NAME : chr  \"ADG parselock X get attempts\" \"ADG parselock X get successes\" \"Batched IO (bound) vector count\" \"Batched IO (full) vector count\" ...\n",
      " $ sumValue_I: num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ sumValue_P: num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " - attr(*, \".internal.selfref\")=<externalptr> \n",
      " - attr(*, \"sorted\")= chr  \"snapHour\" \"STAT_NAME\"\n"
     ]
    }
   ],
   "source": [
    "# Sum up the statistics values of the two CUS DB Inte database instances\n",
    "dtNulled.inte1 <- dtNulled.inte[, list(\"minInterval\" = min(beginInterval), \"maxInterval\" = max(endInterval), \"sumValue\" = sum(offsetValue)),\n",
    "   by = list(SNAP_ID, STAT_NAME, snapHour)]\n",
    "   \n",
    "# Same for the CUS DB Prod\n",
    "dtNulled.prod1 <- dtNulled.prod[, list(\"minInterval\" = min(beginInterval), \"maxInterval\" = max(endInterval), \"sumValue\" = sum(offsetValue)),\n",
    "   by = list(SNAP_ID, STAT_NAME, snapHour)]\n",
    "\n",
    "# Merge the data tables of CUS DB Prod and CUS DB Inte.The snapshots at August 29, 1:00 CEST and later are dropped because CUS DB Prod was restarted.\n",
    "dtNulled <- merge(\n",
    "   dtNulled.inte1[snapHour < as.POSIXct(strptime('2019-08-29 01:00:00', '%Y-%m-%d %H:%M:%S')), list(STAT_NAME, snapHour, sumValue)],\n",
    "   dtNulled.prod1[snapHour < as.POSIXct(strptime('2019-08-29 01:00:00', '%Y-%m-%d %H:%M:%S')), list(STAT_NAME, snapHour, sumValue)],\n",
    "   by=c(\"snapHour\", \"STAT_NAME\"), all=T, suffixes=c(\"_I\", \"_P\"), incomparables=NA)\n",
    "\n",
    "setkeyv(dtNulled, c(\"snapHour\", \"STAT_NAME\"))\n",
    "\n",
    "# Rows with variable sumValue_I holds the statistics values of CUS DB Inte, and rows with variable sumValue_P for CUS DB Prod respectively\n",
    "str(dtNulled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the workspace image with the cleansed data for subsequent analysis\n",
    "This workspace will be imported for parts 2 and 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(dtNulled, file=\"../analysis/R.workspaces/cleansed-data.RData\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
