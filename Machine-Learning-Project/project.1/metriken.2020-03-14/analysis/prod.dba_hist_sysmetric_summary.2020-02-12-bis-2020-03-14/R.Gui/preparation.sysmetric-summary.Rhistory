setwd('C:/data/CAS-ADS/Git.repos/CAS-Applied-Data-Science/Machine-Learning-Project/project.1/metriken.2020-03-14/data/prod.dba_hist_sysmetric_summary.2020-02-12-bis-2020-03-14')
daten <- read.csv2(file="sysmetrics-summary.dsv", sep=";", dec=".", stringsAsFactors=F)
str(daten)
library(data.table)
dt <- data.table(daten)
str(dt)

sTimeTmp <- dt[, as.POSIXct(BEGIN_TIME, format="%Y-%m-%d %H:%M:%S")]
str(sTimeTmp)

sum(is.na(sTimeTmp))
tmpna <- which(is.na(sTimeTmp))
## Toad exportiert von einem Oracle DATE nur den Datumsanteil, wenn der Zeitanteil 00:00:00 ist
## Umwandlung in POSIXct-Format mit vollem Datumsformat schlägt dann fehl.

dt[tmpna,  BEGIN_TIME := paste(BEGIN_TIME, '00:00:00', ' ')]
dt[tmpna, ]

sTimeTmp <- dt[, as.POSIXct(BEGIN_TIME, format="%Y-%m-%d %H:%M:%S")]
sum(is.na(sTimeTmp))

sTime <- trunc(sTimeTmp, units="mins")
dt[, sampleTime := as.POSIXct(sTime)]
setkeyv(dt, c("sampleTime", "METRIC_ID", "GROUP_ID", "INSTANCE_NUMBER"))
str(dt)

## Spaltennamen korrigieren; hat noch BOM des Files
colnames(dt)
dt.names <- colnames(dt)
dt.names[1] <- "SNAP_ID"
dt.names
colnames(dt) <- dt.names
str(dt)

## Überprüfen, ob alle Samples vollständig sind (alle Metriken), oder nicht
daten.metrics <- read.csv2(file="metrics-meta.dsv", sep=";", dec=".", stringsAsFactors=F)
dt.metrics <- data.table(daten.metrics[, c("METRIC_ID", "GROUP_ID")])
setkeyv(dt.metrics, c("METRIC_ID", "GROUP_ID"))
str(dt.metrics)

dt.test <- merge(dt, dt.metrics, by=c("METRIC_ID", "GROUP_ID"), all=T)
setkeyv(dt.test, c("sampleTime", "METRIC_ID", "GROUP_ID"))
str(dt.test)

str(dt.test[is.na(MINVAL), ])
str(dt.test[is.na(MAXVAL), ])
str(dt.test[is.na(AVERAGE), ])
str(dt.test[is.na(STANDARD_DEVIATION), ])
##  --> hat NA-Werte; die wurden aber bereits so importiert; somit alles i.O.

## Quantile für AVERAGE (Median des Mittelwertes etc.)
library(broom)
dt.average.quantile <- dt[ NUM_INTERVAL >= 57 & NUM_INTERVAL <= 63, glance(summary(AVERAGE)), by=list(METRIC_ID, GROUP_ID, INSTANCE_NUMBER)]
setkeyv(dt.average.quantile, c("METRIC_ID", "GROUP_ID", "INSTANCE_NUMBER"))
str(dt.average.quantile)

dt.quantiled <- merge(dt, dt.average.quantile, by=c("METRIC_ID","GROUP_ID","INSTANCE_NUMBER"), all=F)
setkeyv(dt.quantiled, c("SNAP_ID", "METRIC_ID", "GROUP_ID", "INSTANCE_NUMBER"))
str(dt.quantiled)
dt.quantiled

## Messung anhand von AVERAGE und den Quantilen q1 und q3 kategorisieren als 'L' (tief), 'M' (mittel) oder 'H' (hoch)
dt.quantiled[, category := as.factor('x')]
str(dt.quantiled)
dt.quantiled[ AVERAGE < q1, category := as.factor('L')]
dt.quantiled[ AVERAGE > q3, category := as.factor('H')]
dt.quantiled[ AVERAGE <= q3 & AVERAGE >= q1, category := as.factor('M')]
str(dt.quantiled)
dt.quantiled[ category == as.factor('x'), ]
## --> leer

## Datenstruktur für weitere Analyse erzeugen
dt.avg.category <- dt.quantiled[, list(SNAP_ID, METRIC_ID, GROUP_ID, "metricItem" = paste(METRIC_ID, GROUP_ID, category, sep="-"), "category" = as.character(category))]
setkeyv(dt.avg.category, c("SNAP_ID", "METRIC_ID", "GROUP_ID"))
str(dt.avg.category)

str(daten.metrics)
dt.metrics.meta <- data.table(daten.metrics)
setkeyv(dt.metrics.meta, c("METRIC_ID", "GROUP_ID"))

str(dt.metrics.meta)
setwd('C:/data/CAS-ADS/Git.repos/CAS-Applied-Data-Science/Machine-Learning-Project/project.1/metriken.2020-03-14/analysis/prod.dba_hist_sysmetric_summary.2020-02-12-bis-2020-03-14/R.workspaces')

save(dt.avg.category, dt.metrics.meta, file='sysmetrics-summary.category.RData', safe=T)
